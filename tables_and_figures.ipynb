{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MzboPMRNeRHIIiU04qbSbGM31Ce9mR53",
      "authorship_tag": "ABX9TyMyDV5YWH1gRjguiqFR4otk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afonso-tiago/thesis-notebooks/blob/main/tables_and_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intoduction \n",
        "\n",
        "This is one of the complementary notebooks to the bachelor thesis titled \"*Comparing Performance of Different Goal Functionals in Solving PDEs Using Neural Networks*\". It contains the code with wich all tables and figures of the thesis were created. The code was written in a modular way so that a lot of different plots can be created with it. This also means that it should be fairly easy to create plots for new data created with the [tests.ipynb](https://github.com/afonso-tiago/thesis-notebooks/blob/main/tests.ipynb) notebook.\n",
        "\n",
        "> A good way to navigate Google Colaboratory notebooks is by using the built-in table of contents; the first item in the menu bar on the left side of the screen.\n",
        "\n",
        "> Helpful keyboard shortcuts are: \n",
        "* <kbd>Shift</kbd> + <kbd>Enter</kbd>: executes a cell and jump to the next one\n",
        "* <kbd>Ctrl</kbd> + <kbd>Enter</kbd>: executes a cell but stays in that cell"
      ],
      "metadata": {
        "id": "G4Mut9vQUgJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "sdFPoJaSmUGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to run all the cells in this notebook you will need to upload the [logs.zip](https://github.com/afonso-tiago/thesis-notebooks/blob/main/logs.zip) file from the [GitHub repository](https://github.com/afonso-tiago/thesis-notebooks) into your current Colab session.\n",
        "\n",
        "For this you can simply run the next cell."
      ],
      "metadata": {
        "id": "rI7FS1MSUh9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/afonso-tiago/thesis-notebooks/main/logs.zip\n",
        "!unzip logs"
      ],
      "metadata": {
        "id": "qjyUnPR5Vt-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use your own data from your google drive run the next cell. \n",
        "\n",
        "If you have data stored elsewhere you can upload it manually with the build-in file explorer; the last item in the menu bar on the left side of the screen."
      ],
      "metadata": {
        "id": "Epuk44h7dd7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MytauTXFeia1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the next cell to import all necessary libraries"
      ],
      "metadata": {
        "id": "Yh3idEJra4a8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbgFAL92dMHx"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from decimal import Decimal\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "wKy5b-YvmIEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cells in this section of the notebook comprise a small API that help in the creation of different plots. \n",
        "\n",
        "The code can be split up into two parts: \n",
        "1. retreving the desired data (find_minimizers, retrieve_alt_data, find_all)\n",
        "2. plotting the data (plot_PINN_and_DRM_minimizer_separately, plot_PINN_and_DRM_minimizer_together, plot_x_y_hue)"
      ],
      "metadata": {
        "id": "6j58y9_Pe6ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# substitute the substring matching the i-th pattern in patterns \n",
        "# with the i-th replacement string in repls for all i\n",
        "def sub_all(patterns, repls, string):\n",
        "  for pattern, repl in zip(patterns, repls):\n",
        "    string = re.sub(pattern, repl, string)\n",
        "  return string"
      ],
      "metadata": {
        "id": "a_Zd9jy1_MZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizers(dir_paths, groups, filter_include='.', filter_exclude='$impossible', \n",
        "                    metric_PINN='PINN relative_H1_error', metric_DRM='DRM relative_H1_error', \n",
        "                    calc_min=None, calc_PINN_min=lambda values: min(values), calc_DRM_min=lambda values: min(values), verbose=True):\n",
        "  \"\"\"Find all minimizers of the specified groups.\n",
        "\n",
        "  Go through all paths in dir_paths and find for every group in groups \"the best run\"/\"minimizer\".\n",
        "  A run is considered better if its minum calculated by calc_min over all the values belonging to the specified metric \n",
        "  is smaller that the minima of all other runs from the same group.\n",
        "\n",
        "  Args: \n",
        "    dir_paths: A is a list of strings, or a single string\n",
        "               specifing the paths in which to search for \"minimizers\"\n",
        "    groups: A list of regular expressions, i.e. a list of strings. \n",
        "            A run belongs to a group if the path to the run's file (relative from dir_path)\n",
        "            matches the regex of the group.\n",
        "            e.g. \n",
        "            if dir_path = '/content/logs/no weak 2nd derivative/n=10/'\n",
        "            and groups = ['n=10', 'beta=100']\n",
        "            then '/content/logs/no weak 2nd derivative/n=10/beta=100#1' belongs to the group 'beta=100' but NOT 'n=10'\n",
        "    filter_include: A regular expression, which basically defines a white list of paths where we will look for minimizers.\n",
        "                    The default value '.' matches every string.\n",
        "    filter_exclude: A regular expression, which basically defines a black list of paths where we will NOT look for minimizers.\n",
        "                    The default value '$impossible' can never match a string, as '$' signals the end of a string.\n",
        "    metric_PINN: A string with the name of a metric that was recorded for a run using PINNs. \n",
        "                The minimizers of the runs using PINNs will be calculated for this metric.\n",
        "    metric_DRM: A string with the name of a metric that was recorded for a run using the DRM. \n",
        "                The minimizers of the runs using the DRM will be calculated for this metric.\n",
        "    calc_min: A function which takes values as its input and returns a minimum.\n",
        "              This argument, if passed, will overwrite BOTH calc_PINN_min and calc_DRM_min.\n",
        "    calc_PINN_min: A function which takes values as its input and returns a minimum.\n",
        "                  This function is used to determine the minimizer of the runs using PINNs.\n",
        "    calc_DRM_min: A function which takes values as its input and returns a minimum.\n",
        "                  This function is used to determine the minimizer of the runs using the DRM.\n",
        "    verbose: A boolean. When set to True, the goup currently worked on and the found minimizers will be printed.\n",
        "\n",
        "  Returns:\n",
        "    groups: The groups passed as an argument.\n",
        "    min: A list of floats. The i-th value is the minimum of the minimizer of the i-th group.\n",
        "    data: A list of pd.DataFrames. The i-th entry is the raw data of the minimizer of the i-th group.\n",
        "    name: A list of strings. The i-th string is the name of the run corresponding to the minimizer of the i-th group.\n",
        "          The name is the path to the run starting from dir_path.\n",
        "    path: A list of strings. The i-th string is the complete path to the run which corresponds to the i-th group.\"\"\"\n",
        "  # if dir_paths is a string convert it to a list of a single string\n",
        "  # this way the remaining code can always expect a list of strings\n",
        "  if type(dir_paths) == str:\n",
        "    dir_paths = [dir_paths]\n",
        "  # if calc_min is set overwrite calc_PINN_min and calc_DRM_min\n",
        "  if calc_min != None:\n",
        "    calc_PINN_min = calc_min\n",
        "    calc_DRM_min = calc_min\n",
        "\n",
        "  min_PINN, min_DRM = len(groups)*[None], len(groups)*[None]\n",
        "  data_PINN, data_DRM = len(groups)*[None], len(groups)*[None]\n",
        "  name_PINN, name_DRM = len(groups)*[''], len(groups)*['']\n",
        "  path_PINN, path_DRM = len(groups)*[''], len(groups)*['']\n",
        "  # this method will recursively visit nestead folders starting from dir_path\n",
        "  # if a file is reached it will check if it belongs to the group specified by the argument group\n",
        "  # it will then check if the minimum of the corresponding run calculated by calc_(PINN/DRM)_min is the smallest up to this point\n",
        "  # if so, it will save its minimum, name, data and path\n",
        "  def check_path_for_minimizer(path, dir_path, group, index):\n",
        "    # in order to access the variables defined outside this function (and not create new local versions)\n",
        "    # we need to add the keyword nonlocal\n",
        "    nonlocal min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM\n",
        "    for subdir_name in listdir(path):\n",
        "      subpath = join(path, subdir_name)\n",
        "      if not isfile(subpath):\n",
        "        # recursively check nested folders\n",
        "        check_path_for_minimizer(subpath, dir_path, group, index)\n",
        "      else:\n",
        "        name = path.replace(dir_path, '')\n",
        "        # check if the name passes the filters and includes the group\n",
        "        if re.search(filter_include, name) and not re.search(filter_exclude, name) and re.search(group, name):\n",
        "          # gather all the data of the run\n",
        "          event_acc = EventAccumulator(subpath, size_guidance={'tensors': 0}) \n",
        "                                                  # From the docs: \n",
        "                                                  # The size_guidance should be a map from a `tagType` string to an integer \n",
        "                                                  # representing the number of items to keep per tag for items of that `tagType`. \n",
        "                                                  # If the size is 0, all events are stored.\n",
        "          event_acc.Reload()\n",
        "\n",
        "          try:\n",
        "            # save the data for the specified metric\n",
        "            data = pd.DataFrame([(w, s, tf.make_ndarray(t)[()]) for w, s, t in event_acc.Tensors(metric_PINN)],\n",
        "                                      columns=['wall_time', 'step', metric_PINN],)\n",
        "          except:\n",
        "            # an execption occurs if the specified metric was not captured during the run\n",
        "            print('WARNING: An error occured while trying to load ' + metric_PINN + ' from the file ' + subpath)\n",
        "            print('The available tags are ' + str(event_acc.Tags()))\n",
        "            continue\n",
        "          minimum = calc_PINN_min(data[metric_PINN].tolist())\n",
        "          # check if the minimum is the smallest up to this point\n",
        "          if min_PINN[index] == None or minimum < min_PINN[index]:\n",
        "            min_PINN[index] = minimum\n",
        "            data_PINN[index] = data\n",
        "            name_PINN[index] = name\n",
        "            path_PINN[index] = subpath\n",
        "\n",
        "          # repeat the same steps above, this time for the DRM\n",
        "          try:\n",
        "            data = pd.DataFrame([(w, s, tf.make_ndarray(t)[()]) for w, s, t in event_acc.Tensors(metric_DRM)],\n",
        "                                    columns=['wall_time', 'step', metric_DRM],)\n",
        "          except:\n",
        "            print('WARNING: An error occured while trying to load ' + metric_DRM + ' from the file ' + subpath)\n",
        "            print('The available tags are ' + str(event_acc.Tags()))\n",
        "            continue\n",
        "          minimum = calc_DRM_min(data[metric_DRM].tolist())\n",
        "          if min_DRM[index] == None or minimum < min_DRM[index]:\n",
        "            min_DRM[index] = minimum\n",
        "            data_DRM[index] = data\n",
        "            name_DRM[index] = name\n",
        "            path_DRM[index] = subpath\n",
        "  for index, group in enumerate(groups):\n",
        "    if verbose: print(f'determining minimizer of group {group} ...')\n",
        "    for dir_path in dir_paths:\n",
        "      check_path_for_minimizer(dir_path, dir_path, group, index)\n",
        "    if verbose: print(f'minimizer determined! PINN: {name_PINN[index]} DRM: {name_DRM[index]}')\n",
        "  return groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM"
      ],
      "metadata": {
        "id": "OjieeHz7w2GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_alt_data(groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM,\n",
        "                     metric_PINN='PINN relative_H1_error', metric_DRM='DRM relative_H1_error', \n",
        "                     calc_min=None, calc_PINN_min=lambda values: min(values), calc_DRM_min=lambda values: min(values), verbose=True):\n",
        "  \"\"\"Retrieve alternative data for the runs with the specified paths.\n",
        "\n",
        "  Get the complete data for every run saved at path_PINN/DRM\n",
        "  and calculate using the (new) function calc_min the minimum of all the values belonging to the (new) metric specified by metric_PINN/DRM.\n",
        "\n",
        "  Args: \n",
        "    groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM: \n",
        "      The values returned by find_minimizers. Note that this function only really needs path_PINN and path_DRM,\n",
        "      but by accepting all those arguments we can directly chain find_minimizers and retrieve_alt_data.\n",
        "    metric_PINN: A string with the name of a metric that was recorded for a run using PINNs.\n",
        "                 This function will use this (new) metric to retrive alternative data from the runs specified by path_PINN.\n",
        "    metric_DRM: A string with the name of a metric that was recorded for a run using the DRM.\n",
        "                This function will use this (new) metric to retrive alternative data from the runs specified by path_DRM.\n",
        "    calc_min: A function which takes values as its input and returns a minimum.\n",
        "              This argument, if passed, will overwrite BOTH calc_PINN_min and calc_DRM_min.\n",
        "    calc_PINN_min: A function which takes values as its input and returns a minimum.\n",
        "                   This function is used to determine the minimizer of the runs using PINNs.\n",
        "    calc_DRM_min: A function which takes values as its input and returns a minimum.\n",
        "                  This function is used to determine the minimizer of the runs using the DRM.\n",
        "    verbose: A boolean. When set to True, prints the path from which currently alternative data is fetched.\n",
        "\n",
        "  Returns:\n",
        "    groups: The groups passed as an argument.\n",
        "    new_min: A list of floats. The i-th value is the minimum of the minimizer of the i-th group.\n",
        "    new_data: A list of pd.DataFrames. The i-th entry is the raw data of the minimizer of the i-th group.\n",
        "    new_name: A list of strings. The i-th string is the name of the run corresponding to the minimizer of the i-th group.\n",
        "          The name is the path to the run starting from dir_path.\n",
        "    new_path: A list of strings. The i-th string is the complete path to the run which corresponds to the i-th group.\"\"\"\n",
        "  new_min_PINN, new_min_DRM = len(groups)*[None], len(groups)*[None]\n",
        "  new_data_PINN, new_data_DRM = len(groups)*[None], len(groups)*[None]\n",
        "  # if calc_min is set overwrite calc_PINN_min and calc_DRM_min\n",
        "  if calc_min != None:\n",
        "    calc_PINN_min = calc_min\n",
        "    calc_DRM_min = calc_min\n",
        "  # go over all of PINNs' paths\n",
        "  for index, path in enumerate(path_PINN):\n",
        "    if verbose: print(f'retrieving alternative PINN data form {path} ...')\n",
        "    event_acc = EventAccumulator(path, size_guidance={'tensors': 0}) \n",
        "                                                    # From the docs: \n",
        "                                                    # The size_guidance should be a map from a `tagType` string to an integer \n",
        "                                                    # representing the number of items to keep per tag for items of that `tagType`. \n",
        "                                                    # If the size is 0, all events are stored.\n",
        "    event_acc.Reload()\n",
        "\n",
        "    data = pd.DataFrame([(w, s, tf.make_ndarray(t)[()]) for w, s, t in event_acc.Tensors(metric_PINN)],\n",
        "                        columns=['wall_time', 'step', metric_PINN],)\n",
        "    minimum = calc_PINN_min(data[metric_PINN].tolist())\n",
        "    new_data_PINN[index] = data\n",
        "    new_min_PINN[index] = minimum\n",
        "  # go over all of DRM's paths\n",
        "  for index, path in enumerate(path_DRM):\n",
        "    if verbose: print(f'retrieving alternative DRM data form {path} ...')\n",
        "    event_acc = EventAccumulator(path, size_guidance={'tensors': 0}) \n",
        "                                                    # From the docs: \n",
        "                                                    # The size_guidance should be a map from a `tagType` string to an integer \n",
        "                                                    # representing the number of items to keep per tag for items of that `tagType`. \n",
        "                                                    # If the size is 0, all events are stored.\n",
        "    event_acc.Reload()\n",
        "\n",
        "    data = pd.DataFrame([(w, s, tf.make_ndarray(t)[()]) for w, s, t in event_acc.Tensors(metric_DRM)],\n",
        "                                columns=['wall_time', 'step', metric_DRM],)\n",
        "    minimum = calc_DRM_min(data[metric_DRM].tolist())\n",
        "    new_data_DRM[index] = data\n",
        "    new_min_DRM[index] = minimum\n",
        "  return groups, new_min_PINN, new_min_DRM, new_data_PINN, new_data_DRM, name_PINN, name_DRM, path_PINN, path_DRM"
      ],
      "metadata": {
        "id": "Odbxwjj-NnGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_PINN_and_DRM_minimizer_separately(groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM,\n",
        "                                           xlabel='epoch', ylabel=None, figsize=None, suptitle='', patterns=['$impossible'], repls=[''], \n",
        "                                           PINN_visible=True, DRM_visible=True, sharey=True, xscale='linear', yscale='log', \n",
        "                                           markers=[None], colors=[None]): \n",
        "  \"\"\"Create a figure where the \"best run\" of every group is shown in the same plot. \n",
        "  Create one plot for the runs using PINNs on the left and the DRM on the right.\n",
        "  The y-axis is scaled logarithmically by default.\n",
        "\n",
        "  Args: \n",
        "    groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM: \n",
        "      The values returned by find_minimizers or retrieve_alt_data.\n",
        "    ylabel: A string or None. If None is passed, the ylabel will be automatically constructed from \n",
        "            the longest overlap in the names of metric_PINN and metric_DRM, e.g. \n",
        "            if metric_PINN = 'metric PINN relative_L2_error' and metric_DRM = 'metric_DRM_relative_L2_error'\n",
        "            ylabel will become 'relative_L2_error'.\n",
        "    patterns: A list of regular expressions. Replace for all names in name_PINN/DRM the first match with pattern[i] by repls[i].\n",
        "    repls: A list of strings, which replace the matched patterns.\"\"\"\n",
        "  assert PINN_visible or DRM_visible\n",
        "  # if no ylabel was specified change it to the longest overlapping string between metric_PINN and metric_DRM\n",
        "  if ylabel == None:\n",
        "    metric_PINN, metric_DRM = data_PINN[0].columns[-1], data_DRM[0].columns[-1]\n",
        "    sm = SequenceMatcher(None, metric_PINN, metric_DRM)\n",
        "    match = sm.find_longest_match(0,len(metric_PINN),0,len(metric_DRM))\n",
        "    ylabel = metric_PINN[match[0]:match[0]+match[2]]\n",
        "  if len(markers) < len(groups):\n",
        "    markers *= math.ceil(len(groups)/len(markers))\n",
        "  if len(colors) < len(groups):\n",
        "    colors *= math.ceil(len(groups)/len(colors))\n",
        "  # rows is fixed, but by creating a variable for it the remaining code is easier to read\n",
        "  rows, columns = 1, (PINN_visible + DRM_visible)\n",
        "  if figsize == None:\n",
        "    figsize = (6*columns, 4*rows)\n",
        "  fig, ax = plt.subplots(rows, columns, figsize=figsize, sharey=sharey)\n",
        "  # only set different values for ax0 and ax1 when two axis exist\n",
        "  ax0 = ax[0] if PINN_visible and DRM_visible else ax\n",
        "  ax1 = ax[1] if PINN_visible and DRM_visible else ax\n",
        "  for index, group in enumerate(groups):\n",
        "    if PINN_visible:\n",
        "      name = sub_all(patterns, repls, name_PINN[index])\n",
        "      ax0.plot('step', data_PINN[index].columns[-1], data=data_PINN[index], label=name, marker=markers[index], color=colors[index])\n",
        "    if DRM_visible:\n",
        "      name = sub_all(patterns, repls, name_DRM[index])\n",
        "      ax1.plot('step', data_DRM[index].columns[-1], data=data_DRM[index], label=name, marker=markers[index], color=colors[index])\n",
        "  if PINN_visible:\n",
        "    ax0.set(title='PINN', xscale=xscale, yscale=yscale, xlabel=xlabel, ylabel=ylabel)\n",
        "      # sort PINN labels by min\n",
        "    handles, labels = ax0.get_legend_handles_labels()\n",
        "    sorted_mhl = sorted(zip(min_PINN, handles, labels), key=lambda z:z[0], reverse=True)\n",
        "    ax0.legend([h for m,h,l in sorted_mhl], [l for m,h,l in sorted_mhl]) \n",
        "  if DRM_visible:  \n",
        "    ax1.set(title='DRM', xscale=xscale, yscale=yscale, xlabel=xlabel, ylabel=ylabel)\n",
        "      # sort DRM labels by min\n",
        "    handles, labels = ax1.get_legend_handles_labels()\n",
        "    sorted_mhl = sorted(zip(min_DRM, handles, labels), key=lambda z:z[0], reverse=True)\n",
        "    ax1.legend([h for m,h,l in sorted_mhl], [l for m,h,l in sorted_mhl]) \n",
        "  fig.suptitle(suptitle, fontsize=14)\n",
        "  fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "  fig.show()\n",
        "  # return fig, ax"
      ],
      "metadata": {
        "id": "weh5DCOe5G8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_PINN_and_DRM_minimizer_together(groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM,\n",
        "                                         rows = None, columns = None, xlabel='epoch', ylabel=None, figsize=None, suptitle='',\n",
        "                                         patterns=['$impossible'], repls=[''], xscale='linear', yscale='log'):  \n",
        "  \"\"\"Create one plot for every group, where the \"best run\" of this group using PINNs and the DRM are both shown in the same plot.\n",
        "\n",
        "  Args: \n",
        "    groups, min_PINN, min_DRM, data_PINN, data_DRM, name_PINN, name_DRM, path_PINN, path_DRM: \n",
        "      The values returned by find_minimizers or retrieve_alt_data.\n",
        "    rows, columns: Two whole numbers or None. If none are passed columns will default to 1 and rows will grow as needed.\n",
        "                   In general, if only one of the two values is passed the other one will be choosen large enough\n",
        "                   s.t. at least one subplot exists for every group in groups. Exess subplots created this way are left empty.\n",
        "    ylabel: A string or None. If None is passed, the ylabel will be automatically constructed from \n",
        "            the longest overlap in the names of metric_PINN and metric_DRM, e.g. \n",
        "            if metric_PINN = 'metric PINN relative_L2_error' and metric_DRM = 'metric_DRM_relative_L2_error'\n",
        "            ylabel will become 'relative_L2_error'.\n",
        "    patterns: A list of regular expressions. Replace for all names in name_PINN/DRM the first match with pattern[i] by repls[i].\n",
        "    repls: A list of strings, which replace the matched patterns.\"\"\"\n",
        "  if rows == None and columns == None:\n",
        "    columns = 1\n",
        "  if rows == None and columns != None:\n",
        "    # choose rows just large enough s.t. rows*columns >= len(groups)\n",
        "    rows = math.ceil(len(groups) / columns)\n",
        "  if rows != None and columns == None:\n",
        "    # choose columns just large enough s.t. rows*columns >= len(groups)\n",
        "    columns = math.ceil(len(groups) / rows)\n",
        "  # if no ylabel was specified change it to the longest overlapping string between metric_PINN and metric_DRM\n",
        "  if ylabel == None:\n",
        "    metric_PINN, metric_DRM = data_PINN[0].columns[-1], data_DRM[0].columns[-1]\n",
        "    sm = SequenceMatcher(None, metric_PINN, metric_DRM)\n",
        "    match = sm.find_longest_match(0,len(metric_PINN),0,len(metric_DRM))\n",
        "    ylabel = metric_PINN[match[0]:match[0]+match[2]]\n",
        "  if figsize == None:\n",
        "    # if no figure size was passed choose one based on the number of columns and rows\n",
        "    figsize = (6*columns, 4*rows)\n",
        "  fig, ax = plt.subplots(rows, columns, figsize=figsize)\n",
        "  legend_PINN, legend_DRM = [], []\n",
        "  for index in range(rows*columns): \n",
        "    # translate the (1d) index into (2d) row and column\n",
        "    row = index // columns\n",
        "    column = index % columns\n",
        "    # if only one subplot exists (i.e. rows == columns == 1)\n",
        "    # matplotlib does not allow selecting the axis via ax[1, 1]\n",
        "    # as ax in this case is not a tuple\n",
        "    # the following lines manually set ax_i in this and similar case(s)\n",
        "    if rows == columns == 1:\n",
        "      ax_i = ax\n",
        "    elif rows == 1 or columns == 1:\n",
        "      ax_i = ax[index]\n",
        "    else:\n",
        "      ax_i = ax[row, column]\n",
        "    \n",
        "    if len(groups) <= index:\n",
        "      ax_i.set_axis_off()\n",
        "      continue\n",
        "    group = groups[index]\n",
        "\n",
        "    name = sub_all(patterns, repls, name_PINN[index])\n",
        "    ax_i.plot('step', data_PINN[index].columns[-1], data=data_PINN[index], label='PINN: '+name)\n",
        "    name = sub_all(patterns, repls, name_DRM[index])\n",
        "    ax_i.plot('step', data_DRM[index].columns[-1], data=data_DRM[index], label='DRM: '+name)\n",
        "    # reverse the plot order when PINN is below DRM\n",
        "    if min_PINN[index] < min_DRM[index]:\n",
        "      handles, labels = ax_i.get_legend_handles_labels()\n",
        "      ax_i.legend(handles[::-1], labels[::-1]) \n",
        "    ax_i.set(title=group, xscale=xscale, yscale=yscale, xlabel=xlabel, ylabel=ylabel)\n",
        "    fig.suptitle(suptitle, fontsize=14)\n",
        "    fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle"
      ],
      "metadata": {
        "id": "aTq7iPMRwKjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all(dir_paths, filter_include='.', filter_exclude='$impossible', metrics=[],  verbose=True):\n",
        "  \"\"\"For every metric in metrics get the corresponding values from all runs found anywhere under dir_paths.\n",
        "\n",
        "  Args: \n",
        "    dir_paths: A is a list of strings, or a single string\n",
        "               specifing the paths in which to collect the data.\n",
        "    filter_include: A regular expression, which basically defines a white list of paths where we will collect data.\n",
        "                    The default value '.' matches every string.\n",
        "    filter_exclude: A regular expression, which basically defines a black list of paths where we will NOT collect data.\n",
        "                    The default value '$impossible' can never match a string, as '$' signals the end of a string.\n",
        "    metrics: A list of strings, where every element is the name of a metric that was recorded during training. \n",
        "    verbose: A boolean. When set to True, the number of paths (passing the filters) are printed for every (sub) folder.\n",
        "\n",
        "  Returns:\n",
        "    list_vals_map: A list of maps. The i-th map maps the name of a metric to a list \n",
        "                   containing the values of the corresponding metric of the i-th run.\n",
        "    name_list: A list of the names of the runs found.\n",
        "    path_list: A list of the paths to the runs found.\"\"\"\n",
        "  # if dir_paths is a string convert it to a list of a single string\n",
        "  # this way the remaining code can always expect a list of strings\n",
        "  if type(dir_paths) == str:\n",
        "    dir_paths = [dir_paths]\n",
        "\n",
        "  list_vals_map, name_list, path_list = [], [], []\n",
        "  # this method will recursively visit nestead folders starting from dir_path\n",
        "  # if a file is reached it will check if it passes the filters: filter_include and filter_exclude.\n",
        "  # if so, it will save its the values of every metric in metrics to list_vals_map, and name and path to name_list, path_list\n",
        "  def check_path(path, dir_path):\n",
        "    # in order to access the variables defined outside this function (and not create new local versions)\n",
        "    # we need to add the keyword nonlocal\n",
        "    nonlocal list_vals_map, name_list, path_list\n",
        "    for subdir_name in listdir(path):\n",
        "      subpath = join(path, subdir_name)\n",
        "      if not isfile(subpath):\n",
        "        # save length before for verbose output\n",
        "        len_before = len(path_list)\n",
        "        check_path(subpath, dir_path)\n",
        "        if len(listdir(subpath)) > 1:\n",
        "          if verbose: print(f'found {len(path_list) - len_before} file(s) in {subpath.replace(dir_path, \"\")}')\n",
        "      else:\n",
        "        name = path.replace(dir_path, '')\n",
        "        # check if the name passes the filters\n",
        "        if re.search(filter_include, name) and not re.search(filter_exclude, name):\n",
        "          # gather all the data of the run\n",
        "          event_acc = EventAccumulator(subpath, size_guidance={'tensors': 0}) \n",
        "                                                          # From the docs: \n",
        "                                                          # The size_guidance should be a map from a `tagType` string to an integer \n",
        "                                                          # representing the number of items to keep per tag for items of that `tagType`. \n",
        "                                                          # If the size is 0, all events are stored.\n",
        "          event_acc.Reload()\n",
        "          vals_map = {}\n",
        "          for metric in metrics:\n",
        "            vals_map[metric] = [tf.make_ndarray(t)[()] for _, _, t in event_acc.Tensors(metric)] \n",
        "          list_vals_map.append(vals_map)\n",
        "          name_list.append(name)\n",
        "          path_list.append(subpath)\n",
        "\n",
        "  for dir_path in dir_paths:\n",
        "    check_path(dir_path, dir_path)\n",
        "    # this info is always printed (independent of the value of verbose)\n",
        "    print(f'found {len(path_list)} file(s) in {dir_path}')\n",
        "\n",
        "  return list_vals_map, name_list, path_list"
      ],
      "metadata": {
        "id": "GB-EsbDBK6j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def turn_into_x_y_hue(list_vals_map, name_list, path_list, x=None, y=None, hue=None,\n",
        "                      calc_min=None, calc_min_x=lambda x: min(x), calc_min_y=lambda y: min(y), calc_min_hue=lambda h: min(h)):\n",
        "  \"\"\"Turn the data from find_all into x, y, hue values ready to be passed to plot_x_y_hue.\n",
        "\n",
        "  Args: \n",
        "    list_vals_map, name_list, path_list: \n",
        "      The values returned by find_all.\n",
        "    x: A string or a function. If x is a string it has to be one of the metrics in vals_map. \n",
        "       This method will then prepare data_list in such a way that plot_x_y_hue will plot the values \n",
        "       corresponding to this metric on the x-axis. \n",
        "       If x is a function it has to take a values_map as input and return values, \n",
        "       e.g. if we collected both the 'L2' and 'H1' metric but we want to plot their sum on the x-axis\n",
        "       we can do this by passing x: labmda vmap: vmap['L2']+vmap['H1']\n",
        "    y, hue: Similar to x. \n",
        "    calc_min: A function which takes values as its input and returns a minimum.\n",
        "              This argument, if passed, will overwrite calc_min_x, calc_min_y and calc_min_hue.\n",
        "    calc_min_x: A function which takes values as its input and returns a minimum.\n",
        "                This function is used to turn the x values into a single number.\n",
        "    calc_min_y, calc_min_hue: Similar to calc_min_x. \n",
        "\n",
        "  Returns:\n",
        "    data_list: A list of pd.DataFrames, with a column for the x-axis, y-axis and hue-axis.\n",
        "    name_list: A list of the names of the runs whose data is stored in data_list.\n",
        "    path_list: A list of the paths to the runs whose data is stored in data_list.\"\"\"  \n",
        "  # if calc_min is set overwrite calc_min_x, calc_min_y and calc_min_hue.\n",
        "  if calc_min != None:\n",
        "    calc_min_x = calc_min\n",
        "    calc_min_y = calc_min\n",
        "    calc_min_hue = calc_min\n",
        "  x_name, y_name, hue_name = '', '', ''\n",
        "  # if x,y or hue are strings convert them to functions that pick out the metric with their name\n",
        "  # this way the remaining code can always expect x,y, hue to be functions\n",
        "  if type(x) == str:\n",
        "    x_name = x\n",
        "    x = lambda vmap: vmap[x_name]\n",
        "  if type(y) == str:\n",
        "    y_name = y\n",
        "    y = lambda vmap: vmap[y_name]\n",
        "  if type(hue) == str:\n",
        "    hue_name = hue\n",
        "    hue = lambda vmap: vmap[hue_name]\n",
        "  \n",
        "  x_list, y_list, hue_list = [], [], []\n",
        "  for vals_map in list_vals_map:\n",
        "    x_list.append(calc_min_x( x(vals_map) ))\n",
        "    y_list.append(calc_min_y( y(vals_map) ))\n",
        "    hue_list.append(calc_min_hue( hue(vals_map) ))\n",
        "  data_list = pd.DataFrame(zip(x_list, y_list, hue_list), columns=[x_name, y_name, hue_name],)\n",
        "  return data_list, name_list, path_list"
      ],
      "metadata": {
        "id": "ywZzvelZLQ_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_x_y_hue(data_list, name_list, path_list,\n",
        "                 xlabel=None, ylabel=None, huelabel=None, xscale='log', yscale='log', huescale='log',\n",
        "                 figsize=(6,4), suptitle='', cmap='viridis', vmin=None, vmax=None, ax=None):  \n",
        "  \"\"\"Plot the result of turn_into_x_y_hue.\n",
        "\n",
        "  The pd.Dataframe data_list has to contains three columns x, y, hue in this order.\n",
        "  The x and y values is used to create hollow circles at the corresponding positions on the 2d plan\n",
        "  which are colored according to the values in hue.\n",
        "\n",
        "  Args: \n",
        "    data_list, name_list, path_list,\n",
        "      The values returned by turn_into_x_y_hue.\n",
        "    ax: An instance of matplotlib.axes.Axes or None. If this argument is passed, no extra figure is created.\n",
        "        It is assumed that the figure is created outside the method.\"\"\"\n",
        "  if ax == None:\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "  \n",
        "  # the hue values have to be in the third column\n",
        "  hue = data_list.iloc[:,2]\n",
        "  if vmin == None: vmin = hue.min()\n",
        "  if vmax == None: vmax = hue.max()\n",
        "  # save the method of normalizing the colors inside the variable norm \n",
        "  norm = matplotlib.colors.LogNorm() if huescale != 'linear' else matplotlib.colors.Normalize()\n",
        "  s = ax.scatter(x=data_list.iloc[:,0], y=data_list.iloc[:,1], c=hue, cmap='viridis',\n",
        "                 norm=norm, vmin=vmin, vmax=vmax, marker=matplotlib.textpath.TextPath((0, 0), \"◯\"), linewidths=0.1, s=500)\n",
        "  # autolabel the x-,y- and hue-axis if no labels were passed\n",
        "  if xlabel == None: xlabel = data_list.iloc[:,0].name\n",
        "  if ylabel == None: ylabel = data_list.iloc[:,1].name\n",
        "  if huelabel == None: huelabel = hue.name\n",
        "  ax.set(xlabel=xlabel, ylabel=ylabel, xscale=xscale, yscale=yscale)\n",
        "  cbar = plt.colorbar(mappable=s, ax=ax)\n",
        "  cbar.set_label(huelabel)\n",
        "\n",
        "  # show figure if ax was created inside this function\n",
        "  if ax == None:\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "URnfEuUBE2bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Finite Diﬀerences vs Autodiﬀ in High Dimesions"
      ],
      "metadata": {
        "id": "WPv2CP9Z8_9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/logs/runtime/DRM paper d=100/'\n",
        "calc_min = lambda values: sorted(values[int(len(values)*0.8):])[int(len(values)*0.1)]\n",
        "patterns = ['#[0-9]']\n",
        "repls = ['']\n",
        "\n",
        "res = find_minimizers(dir_path, ['autodiff', 'finite diff'], metric_PINN='PINN relative_L2_error', metric_DRM='DRM relative_L2_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res, ylabel='relative L2 error', suptitle='', figsize=(12,5), patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "QI5C9HtkfbbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# re-entrant corners"
      ],
      "metadata": {
        "id": "USHOLAvmmDNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/logs/re-entrant corner/'\n",
        "calc_min = lambda values: sorted(values[int(len(values)*0.8):])[int(len(values)*0.1)]\n",
        "patterns = ['nodes_per_layer=[0-9]*', 'activation=', '/', 'num_blocks']\n",
        "repls = ['', '', ', ', 'blocks']"
      ],
      "metadata": {
        "id": "QDo_q-hp-fPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall best run"
      ],
      "metadata": {
        "id": "sA1gzAAj8Gt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_overall_best = find_minimizers(dir_path, ['0.5xpi', '1.0xpi', '1.5xpi', '2.0xpi'], calc_min=calc_min)\n",
        "\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_overall_best, ylabel='relative H1 error', suptitle='Best overall run', patterns=patterns, repls=repls)\n",
        "\n",
        "plot_PINN_and_DRM_minimizer_together(*res_overall_best, rows = 2, columns = 2, suptitle='Best overall run', patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "TQMjSWDjzhCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Activation"
      ],
      "metadata": {
        "id": "Wi0fsqe68J8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = ['relu_x_div_5_pow_3', 'swish', 'tanh']\n",
        "\n",
        "res_fixed_activation_05 = find_minimizers(dir_path, groups, filter_include='0.5xpi', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_fixed_activation_05, suptitle='Fixed activation best run 0.5xpi')\n",
        "\n",
        "res_fixed_activation_10 = find_minimizers(dir_path, groups, filter_include='1.0xpi', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_fixed_activation_10, suptitle='Fixed activation best run 1.0xpi')\n",
        "\n",
        "res_fixed_activation_15 = find_minimizers(dir_path, groups, filter_include='1.5xpi', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_fixed_activation_15, suptitle='Fixed activation best run 1.5xpi')\n",
        "\n",
        "res_fixed_activation_20 = find_minimizers(dir_path, groups, filter_include='2.0xpi', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_fixed_activation_20, suptitle='Fixed activation best run 2.0xpi')"
      ],
      "metadata": {
        "id": "NVsjTh7Lzi7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_relu_x_div_5_pow_3 = find_minimizers(dir_path, ['#1','#2','#3'], filter_include='(1.0xpi).*(relu_x_div_5_pow_3).*(beta=0.1#)', calc_min=calc_min)\n",
        "ax = plot_PINN_and_DRM_minimizer_separately(*res_relu_x_div_5_pow_3, suptitle='relu_x_div_5_pow_3 beta=0.1', \n",
        "                                            DRM_visible=False, colors=['#8D9EBA', '#5050A8', '#5698C6'])"
      ],
      "metadata": {
        "id": "kLDJBTXWeYTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Penalty Parameter $\\beta$"
      ],
      "metadata": {
        "id": "d1PYbC8C8xYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = ['beta=0.1#', 'beta=1#', 'beta=100#', 'beta=1000#', 'beta=10000#', 'beta=100000#']\n",
        "# note: it is important to add a # after beta=xyz because otherwise (for example) beta=1 would also match beta=100,beta=10000, beta=100000\n",
        "\n",
        "res_05pi = find_minimizers(dir_path, groups, filter_include='0.5xpi', calc_min=calc_min)\n",
        "# plot_PINN_and_DRM_minimizer_separately(*res_05pi, suptitle='Fixed beta best run 0.5xpi')\n",
        "\n",
        "res_10pi = find_minimizers(dir_path, groups, filter_include='1.0xpi', calc_min=calc_min)\n",
        "# plot_PINN_and_DRM_minimizer_separately(*res_10pi, suptitle='Fixed beta best run 1.0xpi')\n",
        "\n",
        "res_15pi = find_minimizers(dir_path, groups, filter_include='1.5xpi', calc_min=calc_min)\n",
        "# plot_PINN_and_DRM_minimizer_separately(*res_15pi, suptitle='Fixed beta best run 1.5xpi')\n",
        "\n",
        "res_20pi = find_minimizers(dir_path, groups, filter_include='2.0xpi', calc_min=calc_min)\n",
        "# plot_PINN_and_DRM_minimizer_separately(*res_20pi, suptitle='Fixed beta best run 2.0xpi')\n",
        "\n",
        "# plot_PINN_and_DRM_minimizer_together(*res_20pi, rows=2, columns=3, suptitle='Fixed beta best run')"
      ],
      "metadata": {
        "id": "UVe1bDUb3DYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = lambda x: '{:.2e}'.format(Decimal(x)) # convert \n",
        "min_PINN_05pi = [conv(x) for x in res_05pi[1]]\n",
        "min_PINN_10pi = [conv(x) for x in res_10pi[1]]\n",
        "min_PINN_15pi = [conv(x) for x in res_15pi[1]]\n",
        "min_PINN_20pi = [conv(x) for x in res_20pi[1]]\n",
        "\n",
        "min_DRM_05pi = [conv(x) for x in res_05pi[2]]\n",
        "min_DRM_10pi = [conv(x) for x in res_10pi[2]]\n",
        "min_DRM_15pi = [conv(x) for x in res_15pi[2]]\n",
        "min_DRM_20pi = [conv(x) for x in res_20pi[2]]"
      ],
      "metadata": {
        "id": "gPTwkUWdyVW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_PINN_05pi[index], min_PINN_10pi[index], min_PINN_15pi[index], min_PINN_20pi[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['0.5xpi', '1.0xpi', '1.5xpi', '2.0xpi'])"
      ],
      "metadata": {
        "id": "2fcUOVlq7B-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_DRM_05pi[index], min_DRM_10pi[index], min_DRM_15pi[index], min_DRM_20pi[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['0.5xpi', '1.0xpi', '1.5xpi', '2.0xpi'])"
      ],
      "metadata": {
        "id": "SO5_cpQYFU6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relations between goal functions and errors"
      ],
      "metadata": {
        "id": "3hJ_3SXVDdcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=['PINN relative_H1_error', 'PINN relative_L2_error', 'PINN relative_L2_error boundary', 'PINN loss_inner', 'PINN loss_boundary',\n",
        "         'DRM relative_H1_error', 'DRM relative_L2_error', 'DRM relative_L2_error boundary', 'DRM loss_inner', 'DRM loss_boundary',]\n",
        "res_all = find_all(dir_path, filter_include='^[0-9].[0-9]xpi', metrics=metrics, verbose=True)"
      ],
      "metadata": {
        "id": "cWRggW9LQ9aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "res_inner_vs_boundary_H1_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_H1_error', calc_min=calc_min)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_H1_color_PINN, ax=ax[0], xlabel='PINN goal_inner', ylabel='PINN goal_boundary')\n",
        "calc_min_x = lambda values: sorted(np.abs(math.pi/4 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_H1_color_DRM = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_H1_error', \n",
        "                                                           calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_H1_color_DRM, ax=ax[1], xlabel='abs diff to optimal Dirichlet energy', ylabel='DRM goal_boundary')\n",
        "\n",
        "fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hZjPkQC3Rp7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# res_inner_vs_boundary_loss_i_color_PINN = turn_into_x_y_hue(*res_all, x='PINN relative_L2_error', y='PINN relative_L2_error boundary', hue='PINN loss_inner', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_loss_i_color_PINN, ax=ax[0], huelabel='PINN goal_inner')\n",
        "# res_inner_vs_boundary_loss_b_color_PINN = turn_into_x_y_hue(*res_all, x='PINN relative_L2_error', y='PINN relative_L2_error boundary', hue='PINN loss_boundary', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_loss_b_color_PINN, ax=ax[1], huelabel='PINN goal_boundary')\n",
        "\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "l5IftCeOSe7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# res_inner_vs_boundary_L2_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_L2_error', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_color_PINN, ax=ax[0], xlabel='PINN goal_inner', ylabel='PINN goal_boundary')\n",
        "# res_inner_vs_boundary_L2_b_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_L2_error boundary', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_b_color_PINN, ax=ax[1], xlabel='PINN goal_inner', ylabel='PINN goal_boundary')\n",
        "\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "luG9_BIbVc2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# calc_min_hue = lambda values: sorted(np.abs(math.pi/4 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_loss_i_color_DRM = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_inner', \n",
        "#                                                            calc_min_x=calc_min, calc_min_y=calc_min, calc_min_hue=calc_min_hue)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_loss_i_color_DRM, ax=ax[0], huelabel='abs diff to optimal Dirichlet energy')\n",
        "# res_inner_vs_boundary_loss_b_color_DRM = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_boundary', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_loss_b_color_DRM, ax=ax[1], huelabel='DRM goal_boundary')\n",
        "\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "34L4E7-eSgbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# calc_min_x = lambda values: sorted(np.abs(math.pi/4 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_L2_color_DRM = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_color_DRM, ax=ax[0], xlabel='abs diff to optimal Dirichlet energy', ylabel='DRM goal_boundary')\n",
        "# res_inner_vs_boundary_L2_b_color_DRM = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error boundary', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_b_color_DRM, ax=ax[1], xlabel='abs diff to optimal Dirichlet energy', ylabel='DRM goal_boundary')\n",
        "\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "MjTrLhwwVbwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# no weak $2^\\mathrm{nd}$ derivative"
      ],
      "metadata": {
        "id": "VrPg4F7ScLbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/logs/no weak 2nd derivatives/'\n",
        "dir_paths = [dir_path+'n=10/', dir_path+'n=50/']\n",
        "calc_min = lambda values: sorted(values[int(len(values)*0.8):])[int(len(values)*0.1)]\n",
        "patterns = ['input_dim=', 'domain.*beta', 'interior.*beta', ', $']\n",
        "repls = ['n=', 'beta', 'beta', '']"
      ],
      "metadata": {
        "id": "a3g8SSIIcP60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## overall best"
      ],
      "metadata": {
        "id": "lBLnOkAUke12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_overall_best = find_minimizers(dir_paths, ['input_dim=10,', 'input_dim=50,'], calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_together(*res_overall_best, rows=1, suptitle='Best overall run', patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "ggBCpOS1c4wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINN_last_err = res_overall_best[3][1]['PINN relative_H1_error'].iat[-1]\n",
        "DRM_last_err = res_overall_best[4][1]['DRM relative_H1_error'].iat[-1]\n",
        "print('PINN last err ', PINN_last_err) \n",
        "print('DRM last err ', DRM_last_err) \n",
        "print('Relative difference ', abs(PINN_last_err - DRM_last_err)/min(PINN_last_err, DRM_last_err))"
      ],
      "metadata": {
        "id": "g6clftE6fPha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## different batch sizes"
      ],
      "metadata": {
        "id": "NSW2oTaAkgln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_few_points_n_10 = find_minimizers(dir_path+'n=10/', ['deep', 'few inner', 'few everywhere'], calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_few_points_n_10, suptitle='Different batch sizes, n=10', patterns=patterns+['deep'], repls=repls+['normal'])\n",
        "\n",
        "res_few_points_n_50 = find_minimizers(dir_path+'n=50/', ['deep', 'few inner', 'few everywhere'], calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_few_points_n_50, suptitle='Different batch sizes, n=50', patterns=patterns+['deep'], repls=repls+['normal'])"
      ],
      "metadata": {
        "id": "C3iF6FALki18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt_res_few_points_n_10 = retrieve_alt_data(*res_few_points_n_10, metric_PINN='PINN relative_L2_error boundary', metric_DRM='DRM relative_L2_error boundary', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*alt_res_few_points_n_10, suptitle='Relative L2 error on boundary, n=10', patterns=patterns+['deep'], repls=repls+['normal'])\n",
        "\n",
        "alt_res_few_points_n_50 = retrieve_alt_data(*res_few_points_n_50, metric_PINN='PINN relative_L2_error boundary', metric_DRM='DRM relative_L2_error boundary', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*alt_res_few_points_n_50, suptitle='Relative L2 error on boundary, n=50', patterns=patterns+['deep'], repls=repls+['normal'])"
      ],
      "metadata": {
        "id": "y_zzJdGnmK7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## difference shallow vs deep"
      ],
      "metadata": {
        "id": "z_HljI1qmn7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n=10\n",
        "res_shallow_and_deep_n_10 = find_minimizers(dir_path+'n=10/', ['num_blocks=3', 'num_blocks=0'], filter_exclude='few', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_shallow_and_deep_n_10, suptitle='Shallow vs Deep, n=10', patterns=patterns, repls=repls)\n",
        "\n",
        "# n=50\n",
        "res_shallow_and_deep_n_50 = find_minimizers(dir_path+'n=50/', ['num_blocks=3', 'num_blocks=0'], filter_exclude='few', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_shallow_and_deep_n_50, suptitle='Shallow vs Deep, n=50', patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "bjtf0AD5mqSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## beta table"
      ],
      "metadata": {
        "id": "WQmqXcf2o-Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = ['beta=0.1#', 'beta=1#', 'beta=100#', 'beta=10000#', 'beta=100000#']\n",
        "# note: it is important to add a # after beta=xyz because otherwise (for example) beta=1 would also match beta=100,beta=10000, beta=100000\n",
        "\n",
        "res_n_10 = find_minimizers(dir_paths, groups, filter_include='input_dim=10,', metric_PINN='PINN relative_H1_error', metric_DRM='DRM relative_H1_error', calc_min=calc_min)\n",
        "res_n_50 = find_minimizers(dir_paths, groups, filter_include='input_dim=50,', metric_PINN='PINN relative_H1_error', metric_DRM='DRM relative_H1_error', calc_min=calc_min)\n",
        "\n",
        "conv = lambda x: '{:.2e}'.format(Decimal(x)) # convert \n",
        "min_PINN_n_10 = [conv(x) for x in res_n_10[1]]\n",
        "min_PINN_n_50 = [conv(x) for x in res_n_50[1]]\n",
        "\n",
        "min_DRM_n_10 = [conv(x) for x in res_n_10[2]]\n",
        "min_DRM_n_50 = [conv(x) for x in res_n_50[2]]"
      ],
      "metadata": {
        "id": "6FOn5mAmpBTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_PINN_n_10[index], min_PINN_n_50[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['n=10', 'n=50'])"
      ],
      "metadata": {
        "id": "lw7DDPK2ldRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_DRM_n_10[index], min_DRM_n_50[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['n=10', 'n=50'])"
      ],
      "metadata": {
        "id": "IOhY5knFlk6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relations between goal functions and errors"
      ],
      "metadata": {
        "id": "7gkUGl0VEfBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=['PINN relative_H1_error', 'PINN relative_L2_error', 'PINN relative_L2_error boundary', 'PINN loss_inner', 'PINN loss_boundary',\n",
        "         'DRM relative_H1_error', 'DRM relative_L2_error', 'DRM relative_L2_error boundary', 'DRM loss_inner', 'DRM loss_boundary',]\n",
        "res_all = find_all(dir_path, filter_include='^n=[0-9]*/', metrics=metrics)"
      ],
      "metadata": {
        "id": "mH1SZ7PgWxnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "res_inner_vs_boundary_H1_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_H1_error', calc_min=calc_min)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_H1_color_PINN, ax=ax[0], \n",
        "             huescale='linear', xlabel='PINN goal_inner', ylabel='PINN goal_boundary')\n",
        "calc_min_x = lambda values: sorted(np.abs(5 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_H1_color_DRM_n_10 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_H1_error', \n",
        "                                                           calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "calc_min_x = lambda values: sorted(np.abs(25 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_H1_color_DRM_n_50 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_H1_error', \n",
        "                                                           calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "res_zip = list(zip(res_inner_vs_boundary_H1_color_DRM_n_10, res_inner_vs_boundary_H1_color_DRM_n_50))\n",
        "res_inner_vs_boundary_H1_color_DRM = []\n",
        "for el in res_zip:\n",
        "  try:\n",
        "    el = pd.concat(el)\n",
        "  except:\n",
        "    el = np.concatenate(el)\n",
        "  finally:\n",
        "    res_inner_vs_boundary_H1_color_DRM.append(el)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_H1_color_DRM, ax=ax[1], \n",
        "             huescale='linear', xlabel='abs diff to optimal Dirichlet energy', ylabel='DRM goal_boundary')\n",
        "\n",
        "fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ajil_6bfjPEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "res_inner_vs_boundary_loss_i_color_PINN = turn_into_x_y_hue(*res_all, x='PINN relative_L2_error', y='PINN relative_L2_error boundary', hue='PINN loss_inner', calc_min=calc_min)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_loss_i_color_PINN, ax=ax[0], xscale='linear', yscale='linear', huelabel='PINN goal_inner')\n",
        "res_inner_vs_boundary_loss_b_color_PINN = turn_into_x_y_hue(*res_all, x='PINN relative_L2_error', y='PINN relative_L2_error boundary', hue='PINN loss_boundary', calc_min=calc_min)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_loss_b_color_PINN, ax=ax[1], xscale='linear', yscale='linear', huelabel='PINN goal_boundary')\n",
        "\n",
        "fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vVu0OJrgW4tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# res_inner_vs_boundary_L2_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_L2_error', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_color_PINN, ax=ax[0], huescale='linear')\n",
        "# res_inner_vs_boundary_L2_b_color_PINN = turn_into_x_y_hue(*res_all, x='PINN loss_inner', y='PINN loss_boundary', hue='PINN relative_L2_error boundary', calc_min=calc_min)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_b_color_PINN, ax=ax[1], huescale='linear')\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "32mgw5fkXC8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# hue = loss_inner\n",
        "calc_min_hue = lambda values: sorted(np.abs(5 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_loss_i_color_DRM_n_10 = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_inner', \n",
        "                                                           calc_min_x=calc_min, calc_min_y=calc_min, calc_min_hue=calc_min_hue)\n",
        "calc_min_hue = lambda values: sorted(np.abs(25 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_loss_i_color_DRM_n_50 = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_inner', \n",
        "                                                           calc_min_x=calc_min, calc_min_y=calc_min, calc_min_hue=calc_min_hue)\n",
        "res_zip = list(zip(res_inner_vs_boundary_loss_i_color_DRM_n_10, res_inner_vs_boundary_loss_i_color_DRM_n_50))\n",
        "res_inner_vs_boundary_loss_i_color_DRM = []\n",
        "for el in res_zip:\n",
        "  try:\n",
        "    el = pd.concat(el)\n",
        "  except:\n",
        "    el = np.concatenate(el)\n",
        "  finally:\n",
        "    res_inner_vs_boundary_loss_i_color_DRM.append(el)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_loss_i_color_DRM, ax=ax[0], xscale='linear', yscale='linear', huescale='linear', huelabel='abs diff to optimal Dirichlet energy')\n",
        "\n",
        "# hue = loss_boundary\n",
        "calc_min_hue = lambda values: sorted(np.abs(5 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_loss_b_color_DRM_n_10 = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_boundary', \n",
        "                                                           calc_min_x=calc_min, calc_min_y=calc_min, calc_min_hue=calc_min_hue)\n",
        "calc_min_hue = lambda values: sorted(np.abs(25 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "res_inner_vs_boundary_loss_b_color_DRM_n_50 = turn_into_x_y_hue(*res_all, x='DRM relative_L2_error', y='DRM relative_L2_error boundary', hue='DRM loss_boundary', \n",
        "                                                           calc_min_x=calc_min, calc_min_y=calc_min, calc_min_hue=calc_min_hue)\n",
        "res_zip = list(zip(res_inner_vs_boundary_loss_b_color_DRM_n_10, res_inner_vs_boundary_loss_b_color_DRM_n_50))\n",
        "res_inner_vs_boundary_loss_b_color_DRM = []\n",
        "for el in res_zip:\n",
        "  try:\n",
        "    el = pd.concat(el)\n",
        "  except:\n",
        "    el = np.concatenate(el)\n",
        "  finally:\n",
        "    res_inner_vs_boundary_loss_b_color_DRM.append(el)\n",
        "plot_x_y_hue(*res_inner_vs_boundary_loss_b_color_DRM, ax=ax[1], xscale='linear', yscale='linear', huescale='linear', huelabel='DRM goal_boundary')\n",
        "\n",
        "fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "feQxTTksXGn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# # hue = relative_L2_error\n",
        "# calc_min_x = lambda values: sorted(np.abs(5 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_L2_color_DRM_n_10 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# calc_min_x = lambda values: sorted(np.abs(25 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_L2_color_DRM_n_50 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# res_zip = list(zip(res_inner_vs_boundary_L2_color_DRM_n_10, res_inner_vs_boundary_L2_color_DRM_n_50))\n",
        "# res_inner_vs_boundary_L2_color_DRM = []\n",
        "# for el in res_zip:\n",
        "#   try:\n",
        "#     el = pd.concat(el)\n",
        "#   except:\n",
        "#     el = np.concatenate(el)\n",
        "#   finally:\n",
        "#     res_inner_vs_boundary_L2_color_DRM.append(el)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_color_DRM, ax=ax[0], xscale='linear', yscale='linear', huescale='linear', xlabel='abs diff to optimal Dirichlet energy')\n",
        "\n",
        "# # hue = relative_L2_error boundary\n",
        "# calc_min_x = lambda values: sorted(np.abs(5 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_L2_b_color_DRM_n_10 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error boundary', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# calc_min_x = lambda values: sorted(np.abs(25 -np.array(values[int(len(values)*0.8):])))[int(len(values)*0.1)]\n",
        "# res_inner_vs_boundary_L2_b_color_DRM_n_50 = turn_into_x_y_hue(*res_all, x='DRM loss_inner', y='DRM loss_boundary', hue='DRM relative_L2_error boundary', \n",
        "#                                                            calc_min_x=calc_min_x, calc_min_y=calc_min, calc_min_hue=calc_min)\n",
        "# res_zip = list(zip(res_inner_vs_boundary_L2_b_color_DRM_n_10, res_inner_vs_boundary_L2_b_color_DRM_n_50))\n",
        "# res_inner_vs_boundary_L2_b_color_DRM = []\n",
        "# for el in res_zip:\n",
        "#   try:\n",
        "#     el = pd.concat(el)\n",
        "#   except:\n",
        "#     el = np.concatenate(el)\n",
        "#   finally:\n",
        "#     res_inner_vs_boundary_L2_b_color_DRM.append(el)\n",
        "# plot_x_y_hue(*res_inner_vs_boundary_L2_b_color_DRM, ax=ax[1], xscale='linear', yscale='linear', huescale='linear', xlabel='abs diff to optimal Dirichlet energy')\n",
        "\n",
        "# fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "Ntu7PKO3X_CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the $2^\\mathrm{nd}$ derivative explodes"
      ],
      "metadata": {
        "id": "7y5MmvdzcHij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/logs/exploding 2nd derivatives/'\n",
        "dir_paths = [dir_path+'n=10/', dir_path+'n=100/']\n",
        "calc_min = lambda values: sorted(values[int(len(values)*0.8):])[int(len(values)*0.1)]\n",
        "patterns = ['input_dim=', 'num.*beta', 'interior.*beta', ', $']\n",
        "repls = ['n=', 'beta', 'beta', '']"
      ],
      "metadata": {
        "id": "pvkqeHnicmN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## overall best"
      ],
      "metadata": {
        "id": "_kSmwr6Fmn2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_overall_best = find_minimizers(dir_paths, ['input_dim=10,', 'input_dim=100,'], metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_together(*res_overall_best, rows=1, suptitle='Best overall run', patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "U9vwy_BwlIBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINN_last_err = res_overall_best[3][0]['PINN relative_C1_error'].iat[-1]\n",
        "DRM_last_err = res_overall_best[4][0]['DRM relative_C1_error'].iat[-1]\n",
        "print('PINN last err ', PINN_last_err) \n",
        "print('DRM last err ', DRM_last_err) \n",
        "print('Relative difference ', abs(PINN_last_err - DRM_last_err)/min(PINN_last_err, DRM_last_err))"
      ],
      "metadata": {
        "id": "KjZF3TnmmStN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## different batch sizes"
      ],
      "metadata": {
        "id": "unpTuoau1_wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_few_points_n_10 = find_minimizers(dir_path+'n=10/', ['shallow', 'few inner', 'few everywhere'], metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_few_points_n_10, suptitle='Different batch sizes, n=10', patterns=patterns+['shallow'], repls=repls+['normal'])\n",
        "\n",
        "res_few_points_n_100 = find_minimizers(dir_path+'n=100/', ['shallow', 'few inner', 'few everywhere'], metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_few_points_n_100, suptitle='Different batch sizes, n=100', patterns=patterns+['shallow'], repls=repls+['normal'])"
      ],
      "metadata": {
        "id": "zAxFSJLt2IYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt_res_few_points_n_10 = retrieve_alt_data(*res_few_points_n_10, metric_PINN='PINN relative_L_oo_error boundary', metric_DRM='DRM relative_L_oo_error boundary', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*alt_res_few_points_n_10, suptitle='Relative L_inf error on boundary, n=10', ylabel='relative_L_inf_error boundary', patterns=patterns+['shallow'], repls=repls+['normal'])\n",
        "\n",
        "alt_res_few_points_n_100 = retrieve_alt_data(*res_few_points_n_100, metric_PINN='PINN relative_L_oo_error boundary', metric_DRM='DRM relative_L_oo_error boundary', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*alt_res_few_points_n_100, suptitle='Relative L_inf error on boundary, n=100', ylabel='relative_L_inf_error boundary', patterns=patterns+['shallow'], repls=repls+['normal'])"
      ],
      "metadata": {
        "id": "aauYz4NpSpSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_few_points_n_10_L_inf = find_minimizers(dir_path+'n=10/', ['shallow', 'few inner', 'few everywhere'], metric_PINN='PINN relative_L_oo_error', metric_DRM='DRM relative_L_oo_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_few_points_n_10_L_inf, suptitle='L_inf, n=10', ylabel='relative_L_inf_error', DRM_visible=False, patterns=patterns+['shallow'], repls=repls+['normal'])\n",
        "\n",
        "alt_res_few_points_n_10_L_inf = retrieve_alt_data(*res_few_points_n_10_L_inf, metric_PINN='PINN relative_L_oo_error boundary', metric_DRM='DRM relative_L_oo_error boundary', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*alt_res_few_points_n_10_L_inf, suptitle='Relative L_inf error on boundary, n=10', ylabel='relative_L_inf_error boundary', DRM_visible=False, patterns=patterns+['shallow'], repls=repls+['normal'])"
      ],
      "metadata": {
        "id": "Y4OxFiFyW2_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## difference shallow and deep"
      ],
      "metadata": {
        "id": "Ztr3xK3tmp-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n=10\n",
        "res_shallow_and_deep_n_10 = find_minimizers(dir_path+'n=10/', ['num_blocks=3', 'num_blocks=0'], filter_exclude='few', metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_shallow_and_deep_n_10, suptitle='Shallow vs Deep, n=10', patterns=patterns, repls=repls)\n",
        "\n",
        "# n=100\n",
        "res_shallow_and_deep_n_100 = find_minimizers(dir_path+'n=100/', ['num_blocks=3', 'num_blocks=0'], filter_exclude='few', metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "plot_PINN_and_DRM_minimizer_separately(*res_shallow_and_deep_n_100, suptitle='Shallow vs Deep, n=100', patterns=patterns, repls=repls)"
      ],
      "metadata": {
        "id": "lzaEI0G2mf4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# long epochs tests\n",
        "def plot_shallow_vs_deep_lots_of_epochs():\n",
        "  dir_path = '/content/logs/exploding 2nd derivatives/'\n",
        "  names = [('deep, input_dim=10, num_blocks=3, nodes_per_layer=10#1/beta=10000#1', 'shallow, input_dim=10, num_blocks=0, nodes_per_layer=100#1/beta=1#1',), \n",
        "           ('deep, input_dim=10, num_blocks=3, nodes_per_layer=10#1/beta=100#1', 'shallow, input_dim=10, num_blocks=0, nodes_per_layer=100#1/beta=100#1'), \n",
        "           ('deep, input_dim=100, num_blocks=3, nodes_per_layer=100#1/beta=100000#1', 'shallow, input_dim=100, num_blocks=0, nodes_per_layer=100#1/beta=10000#1'), \n",
        "           ('deep, input_dim=100, num_blocks=3, nodes_per_layer=100#1/beta=100000#1', 'shallow, input_dim=100, num_blocks=0, nodes_per_layer=100#1/beta=100#1'),]\n",
        "  index = 0\n",
        "  for n in [10, 100]:\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
        "    for i, method in enumerate(['PINN', 'DRM']):\n",
        "      metric = method+' relative_H1_error'\n",
        "      for j, network in enumerate(['deep', 'shallow']):\n",
        "        color = '#5698C6' if network == 'deep' else '#FF9E4A'\n",
        "        for epochs in [f'n={n}/', 'epochs=50000/']:\n",
        "          name = names[index][j]\n",
        "          \n",
        "          event_acc = EventAccumulator(dir_path + epochs + name, size_guidance={'tensors': 0}) \n",
        "          event_acc.Reload()\n",
        "          data = pd.DataFrame([(w, s, tf.make_ndarray(t)[()]) for w, s, t in event_acc.Tensors(metric)], columns=['wall_time', 'step', metric],)\n",
        "\n",
        "          if epochs == 'epochs=50000/':\n",
        "            label = sub_all(patterns, repls, name)\n",
        "            linestyle = 'solid'\n",
        "          else:\n",
        "            label = None\n",
        "            linestyle = 'dotted'\n",
        "          sns.lineplot(data=data, x='step', y=metric, ax=ax[i], label=label, linestyle=linestyle, color=color)\n",
        "      ax[i].set(title=method, xlabel='epoch', ylabel='relative_C1_error')\n",
        "      index += 1\n",
        "    plt.yscale('log')\n",
        "    fig.suptitle(f'Shallow vs Deep, lots of epochs, n={n}', fontsize=14)\n",
        "    fig.tight_layout(rect=[0,0,1,0.95]) # tight_layout fixes overlapping labels and rect is necessary for clean suptitle\n",
        "    fig.show()\n",
        "\n",
        "plot_shallow_vs_deep_lots_of_epochs()"
      ],
      "metadata": {
        "id": "v6AgK6ApdA4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## beta table"
      ],
      "metadata": {
        "id": "FZt-508aJDSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = ['beta=0.1#', 'beta=1#', 'beta=100#', 'beta=10000#', 'beta=100000#']\n",
        "# note: it is important to add a # after beta=xyz because otherwise (for example) beta=1 would also match beta=100,beta=10000, beta=100000\n",
        "\n",
        "res_n_10 = find_minimizers(dir_paths, groups, filter_include='input_dim=10,', metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "res_n_100 = find_minimizers(dir_paths, groups, filter_include='input_dim=100,', metric_PINN='PINN relative_C1_error', metric_DRM='DRM relative_C1_error', calc_min=calc_min)\n",
        "\n",
        "conv = lambda x: '{:.2e}'.format(Decimal(x)) # convert \n",
        "min_PINN_n_10 = [conv(x) for x in res_n_10[1]]\n",
        "min_PINN_n_100 = [conv(x) for x in res_n_100[1]]\n",
        "\n",
        "min_DRM_n_10 = [conv(x) for x in res_n_10[2]]\n",
        "min_DRM_n_100 = [conv(x) for x in res_n_100[2]]"
      ],
      "metadata": {
        "id": "-LnbHYz4s8Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_PINN_n_10[index], min_PINN_n_100[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['n=10', 'n=100'])"
      ],
      "metadata": {
        "id": "BwCzzpxpMSM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={group: [min_DRM_n_10[index], min_DRM_n_100[index]] \n",
        "                   for index, group in enumerate(groups)}, index=['n=10', 'n=100'])"
      ],
      "metadata": {
        "id": "cX4PxEycMcVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}